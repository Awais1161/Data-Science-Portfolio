# Data Science Portfolio
This repository serves as a showcase of my data science projects, completed for both academic and personal development purposes. Each project is presented in the form of a Jupyter notebook, detailing the methodology and results of my analysis. These projects reflect my ongoing efforts to expand my knowledge and skills in the field of data science.


## Contents

- # Machine Learning


	- [Statistical Analysis on Factors Influencing Life Expectancy](https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Life%20Expectancy/Life%20Expectancy%20Prediction%20%20(Part_1).ipynb): Using supervised machine learning algorithms, “Life Expectancy” rates were predicted based on various impacting factors. After testing multiple algorithms and performing hyper‑parameter tuning, the Random Forest model achieved the highest R2 score of 96.6%.
    
    - [Data Scientist Job Change Prediction](https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Job%20Change%20Prediction/Job%20Change%20Prediction%20%20(Part_1).ipynb): After evaluating various models, it was determined that the Random Forest algorithm had the highest accuracy in predicting employee retention, with a prediction accuracy of 77%. The model indicated that more than 50% of employees are unlikely to change jobs, indicating a low turnover rate.

- # Exploratory Data Analysis

Exploratory Data Analysis is a method of evaluating or comprehending data in order to derive insights or key characteristics. EDA can be divided into two categories: graphical analysis and non-graphical analysis. EDA is a critical component of any data science or machine learning process. It is very crucial to explore the data, understand the relationships between variables, and the underlying structure of the data in order to build a reliable and valuable output based on it. 

The detailed stepwise EDA is carried out here on different datasets using the Python programming language.

\# | Description | Notebook
--- | --- | ---
1 | Credit Risk Dataset | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Exploratory%20Data%20Analysis/Credit%20Risk%20Dataset.ipynb"> View code</a> 
2 | House Prices Dataset | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Exploratory%20Data%20Analysis/House%20Prices%20Dataset.ipynb"> View code</a>
3 | Zomato Restaurants Dataset | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Exploratory%20Data%20Analysis/Zomato%20Restaurants%20Dataset.ipynb"> View code</a>

- # Feature Engineering

Feature Engineering is the process of extracting features from raw data using the domain knowledge of the problem. These features can be used to improve the performance of machine learning algorithms Feature engineering is the most important art in machine learning as it is considered as heart of any Machine Learning model. How successful a model is or how accurately it predicts that depends on the application of various feature engineering techniques. Here, some feature engineering techniques are explained well.

\# | Description | Notebook
--- | --- | ---
1 | Missing Data Imputation | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Handling%20Missing%20Values.ipynb"> View code</a> 
2 | Categorical Encoding | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Categorical%20Encoding.ipynb"> View code</a>
3 | Count Encoding | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Count%20Encoding.ipynb"> View code</a>
4 | Ordinal Encoding | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Ordinal%20Encoding.ipynb"> View code</a>
5 | Imbalanced Dataset |</a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Handling%20Imbalanced%20Dataset.ipynb"> View code</a>
6 | Outlier Engineering | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Handling%20Outliers.ipynb"> View code</a>
7 | Feature Engineering Project | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Feature%20Engineering%20on%20Flight%20Price%20Dataset.ipynb"> View code</a>

- # Feature Selection

While developing the machine learning model, only a few variables in the dataset are useful for building the model, and the rest features are either redundant or irrelevant. If we input the dataset with all these redundant and irrelevant features, it may negatively impact and reduce the overall performance and accuracy of the model. Hence it is very important to identify and select the most appropriate features from the data and remove the irrelevant or less important features, which is done with the help of feature selection in machine learning.
- **Implementation of different feature selection methods with scikit-learn:**

\# | Description | Notebook
--- | --- | ---
1 | Feature Selections Techniques | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Feature%20Selections%20Techniques.ipynb"> View code</a> 
2 | Principal Component Analysis (PCA) | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Principal%20Component%20Analysis%20(PCA).ipynb"> View code</a>
3 | Linear Discriminant Analysis (LDA) | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Linear%20Discriminant%20Analysis%20(LDA).ipynb"> View code</a>


- # Feature Transformation

Feature transformation is a technique by which machine learning model's performance can be enhanced . It is a mathematical transformation in which a mathematical formula is applied to a particular column(feature) and transform the values which are useful for our further analysis.In this notebook, the important feature transformation techniques are discussed in machine learning which are used to transform the data from one form to another form, keeping the essence of the data. In simple words, the transformers are the type of functions that are applied to data that is not normally distributed, and once applied there is a high of getting normally distributed data.

\# | Description | Notebook
--- | --- | ---
1 | Feature Transformation Techniques | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Feature%20Transformations.ipynb"> View code</a> 


