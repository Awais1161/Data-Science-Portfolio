# Data Science Portfolio
This repository serves as a showcase of my data science projects, completed for both academic and personal development purposes. Each project is presented in the form of a Jupyter notebook, detailing the methodology and results of my analysis. These projects reflect my ongoing efforts to expand my knowledge and skills in the field of data science.


## Contents

- # Machine Learning


	- [Statistical Analysis on Factors Influencing Life Expectancy](https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Life%20Expectancy/Life%20Expectancy%20Prediction%20%20(Part_1).ipynb): Using supervised machine learning algorithms, “Life Expectancy” rates were predicted based on various impacting factors. After testing multiple algorithms and performing hyper‑parameter tuning, the Random Forest model achieved the highest R2 score of 96.6%.
    
    - [Data Scientist Job Change Prediction](https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Job%20Change%20Prediction/Job%20Change%20Prediction%20%20(Part_1).ipynb): After evaluating various models, it was determined that the Random Forest algorithm had the highest accuracy in predicting employee retention, with a prediction accuracy of 77%. The model indicated that more than 50% of employees are unlikely to change jobs, indicating a low turnover rate.

- # Exploratory Data Analysis

Exploratory Data Analysis is a method of evaluating or comprehending data in order to derive insights or key characteristics. EDA can be divided into two categories: graphical analysis and non-graphical analysis. EDA is a critical component of any data science or machine learning process. It is very crucial to explore the data, understand the relationships between variables, and the underlying structure of the data in order to build a reliable and valuable output based on it. 

The detailed stepwise EDA is carried out here on different datasets using the Python programming language.

\# | Description | Links
--- | --- | ---
1 | Credit Risk Dataset | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Exploratory%20Data%20Analysis/Credit%20Risk%20Dataset.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a> 
2 | House Prices Dataset | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Exploratory%20Data%20Analysis/House%20Prices%20Dataset.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
3 | Zomato Restaurants Dataset | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Exploratory%20Data%20Analysis/Zomato%20Restaurants%20Dataset.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>

- # Feature Engineering

Feature Engineering is the process of extracting features from raw data using the domain knowledge of the problem. These features can be used to improve the performance of machine learning algorithms Feature engineering is the most important art in machine learning as it is considered as heart of any Machine Learning model. How successful a model is or how accurately it predicts that depends on the application of various feature engineering techniques. Here, some feature engineering techniques are explained well.


Click <img src="icons/nb.svg" width="20px" align="top"> to view the **Jupyter notebook**.

\# | Description | Links
--- | --- | ---
1 | Missing Data Imputation | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Handling%20Missing%20Values.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a> 
2 | Categorical Encoding | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Categorical%20Encoding.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
3 | Count Encoding | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Count%20Encoding.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
4 | Ordinal Encoding | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Ordinal%20Encoding.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
5 | Imbalanced Dataset |</a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Handling%20Imbalanced%20Dataset.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
6 | Outlier Engineering | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Handling%20Outliers.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
7 | Feature Engineering Project | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Feature%20Engineering%20on%20Flight%20Price%20Dataset.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>

- # Feature Selection

While developing the machine learning model, only a few variables in the dataset are useful for building the model, and the rest features are either redundant or irrelevant. If we input the dataset with all these redundant and irrelevant features, it may negatively impact and reduce the overall performance and accuracy of the model. Hence it is very important to identify and select the most appropriate features from the data and remove the irrelevant or less important features, which is done with the help of feature selection in machine learning.
- **Implementation of different feature selection methods with scikit-learn:**

\# | Description | Links
--- | --- | ---
1 | Feature Selections Techniques | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Feature%20Selections%20Techniques.ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a> 
2 | Principal Component Analysis (PCA) | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Principal%20Component%20Analysis%20(PCA).ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
3 | Linear Discriminant Analysis (LDA) | </a> <a href="https://github.com/Awais1161/Data-Science-Portfolio/blob/main/Feature%20Engineering/Linear%20Discriminant%20Analysis%20(LDA).ipynb"><img src="icons/nb.svg" width="20px" align="top" title="View code"></a>
